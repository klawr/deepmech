\section{First prototype} \label{ch:first_prototype}

To create a first prototype capable of detecting hand-drawn mechanism, various capabilities have to be considered.
The application has to be able to detect \name{nodes}, \name{constraints}, which are connecting \name{nodes} and to transform this information into a usable format.

\subsection{The Fully Connected Convolutional Neural Network}.

The topic of a previous work was the recognition of hand-drawn mechanical symbols \cite{Lawrence2020}.
Building on this, the trained model is improved to provide not only the class, but the location of the classification in an image of arbitrary size.

The respective model can be loaded using \name{Keras'}, % TODO citation should be in the introduction.
\code{model.load\_model} and by issuing the \code{summary} method we get listing~\ref{lst:srp_model}.

\begin{lstlisting}[caption={Summary of Symbol Classifier}, label={lst:srp_model}]
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d (Conv2D)              (None, 32, 32, 16)        272
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 16, 16, 16)        0
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 16, 16, 32)        8224
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 8, 8, 32)          0
_________________________________________________________________
flatten (Flatten)            (None, 2048)              0
_________________________________________________________________
dense (Dense)                (None, 3)                 6147
=================================================================
Total params: 14,643
Trainable params: 14,643
Non-trainable params: 0
_________________________________________________________________
\end{lstlisting}

One way to localize images in a bigger image is to scan an image.
Using a stride of one in each direction the number of images which have to be predicted is $h + 1 - 32 * w + 1 - 32$, where $h$ and $w$ are the height and width of the input image and the size of the kernel used to predict is 32.
This would result in 108.241 images to predict for a 360x360 input image.
A Jupyter notebook to test the performance on this can be found at \url{https://aka.klawr.de/sep#1}. % TODO Set this URL.

