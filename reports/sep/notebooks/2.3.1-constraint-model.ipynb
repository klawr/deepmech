{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constraint detecting model\n",
    "\n",
    "In this notebook the model to detect constraints is trained.\n",
    "\n",
    "In previous notebooks the data for this process has been generated.\n",
    "In this notebook the architecture of the model is defined.\n",
    "The model is then trained to check if the results are good enough to proceed.\n",
    "\n",
    "First the prepared data has to be loaded.\n",
    "\n",
    "The dataset is split into three parts.\n",
    "The training set containts 100.000 images, the validation set 20.000 and the test set contains the rest of the 119.190 images (19.190).\n",
    "\n",
    "`src.utils.decode_image_record` can not be used here, because it needs the data to be split before calling it.\n",
    "Thoughts on the improvement to the data generation process can be read in the conclusion to this first prototype in the report-document."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from os import path\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_path = path.join('data', 'sep_processed_01', 'crops.tfrecord')\n",
    "\n",
    "feature_description = {\n",
    "    'image': tf.io.FixedLenFeature([], tf.string),\n",
    "    'label': tf.io.FixedLenFeature([], tf.int64)\n",
    "}\n",
    "\n",
    "def decode(example):\n",
    "    feature = tf.io.parse_single_example(example, feature_description)\n",
    "    image = tf.io.parse_tensor(feature['image'], tf.float32)\n",
    "    image.set_shape((96, 96, 1))\n",
    "    label = feature['label']\n",
    "    return [image, label]\n",
    "\n",
    "dataset = tf.data.TFRecordDataset(record_path).shuffle(1000)\n",
    "\n",
    "def sanitize_dataset(ds):\n",
    "    autotune = tf.data.experimental.AUTOTUNE\n",
    "    return (ds\n",
    "        .map(decode, num_parallel_calls=autotune)    \n",
    "        .cache()\n",
    "        .repeat()\n",
    "        .batch(32)\n",
    "        .prefetch(buffer_size=autotune))\n",
    "\n",
    "train = sanitize_dataset(dataset.take(80000))\n",
    "validate = sanitize_dataset(dataset.skip(80000).take(20000))\n",
    "test = sanitize_dataset(dataset.skip(100000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a baseline the model trained in the `srp` is used.\n",
    "The only difference is that the input layer expects 96 by 96 images.\n",
    "\n",
    "This time the model is created using the functional API, which holds no functional differences here."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 96, 96, 1)]       0         \n_________________________________________________________________\nconv2d (Conv2D)              (None, 96, 96, 16)        272       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 48, 48, 16)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 48, 48, 32)        8224      \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n_________________________________________________________________\nflatten (Flatten)            (None, 18432)             0         \n_________________________________________________________________\ndense (Dense)                (None, 3)                 55299     \n=================================================================\nTotal params: 63,795\nTrainable params: 63,795\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(96, 96, 1))\n",
    "m = tf.keras.layers.Conv2D(16, (4,4), activation='relu', padding='same')(inputs)\n",
    "m = tf.keras.layers.MaxPooling2D(2,2)(m)\n",
    "m = tf.keras.layers.Conv2D(32, (4,4), activation='relu', padding='same')(m)\n",
    "m = tf.keras.layers.MaxPooling2D(2,2)(m)\n",
    "m = tf.keras.layers.Flatten()(m)\n",
    "outputs = tf.keras.layers.Dense(3, 'softmax')(m)\n",
    "\n",
    "model = tf.keras.Model(inputs = inputs, outputs = outputs)\n",
    "\n",
    "log_dir = path.join('logs', 'sep231', datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\"))\n",
    "model_path = path.join('models', 'devel', 'crop_detector.h5')\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, embeddings_freq=1),\n",
    "    tf.keras.callbacks.ModelCheckpoint(model_path, save_best_only=True)]\n",
    "\n",
    "model.compile(\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    metrics   = ['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train for 100 steps, validate for 30 steps\nEpoch 1/60\n100/100 [==============================] - 9s 91ms/step - loss: 0.4541 - acc: 0.8388 - val_loss: 0.3863 - val_acc: 0.8271\nEpoch 2/60\n100/100 [==============================] - 6s 56ms/step - loss: 0.3321 - acc: 0.8681 - val_loss: 0.2932 - val_acc: 0.8854\nEpoch 3/60\n100/100 [==============================] - 5s 55ms/step - loss: 0.2868 - acc: 0.8881 - val_loss: 0.2458 - val_acc: 0.9104\nEpoch 4/60\n100/100 [==============================] - 5s 55ms/step - loss: 0.2395 - acc: 0.9044 - val_loss: 0.2294 - val_acc: 0.9083\nEpoch 5/60\n100/100 [==============================] - 5s 55ms/step - loss: 0.2087 - acc: 0.9150 - val_loss: 0.2058 - val_acc: 0.9250\nEpoch 6/60\n100/100 [==============================] - 6s 56ms/step - loss: 0.2065 - acc: 0.9194 - val_loss: 0.1906 - val_acc: 0.9240\nEpoch 7/60\n100/100 [==============================] - 6s 57ms/step - loss: 0.1812 - acc: 0.9294 - val_loss: 0.1692 - val_acc: 0.9354\nEpoch 8/60\n100/100 [==============================] - 6s 57ms/step - loss: 0.1915 - acc: 0.9328 - val_loss: 0.1830 - val_acc: 0.9281\nEpoch 9/60\n100/100 [==============================] - 6s 57ms/step - loss: 0.1820 - acc: 0.9306 - val_loss: 0.1370 - val_acc: 0.9531\nEpoch 10/60\n100/100 [==============================] - 6s 56ms/step - loss: 0.1532 - acc: 0.9406 - val_loss: 0.1305 - val_acc: 0.9510\nEpoch 11/60\n100/100 [==============================] - 6s 56ms/step - loss: 0.1571 - acc: 0.9434 - val_loss: 0.1542 - val_acc: 0.9427\nEpoch 12/60\n100/100 [==============================] - 6s 56ms/step - loss: 0.1459 - acc: 0.9434 - val_loss: 0.1413 - val_acc: 0.9427\nEpoch 13/60\n100/100 [==============================] - 6s 57ms/step - loss: 0.1316 - acc: 0.9506 - val_loss: 0.1399 - val_acc: 0.9500\nEpoch 14/60\n100/100 [==============================] - 7s 72ms/step - loss: 0.1381 - acc: 0.9506 - val_loss: 0.1772 - val_acc: 0.9333\nEpoch 15/60\n100/100 [==============================] - 6s 64ms/step - loss: 0.1443 - acc: 0.9459 - val_loss: 0.1227 - val_acc: 0.9500\nEpoch 16/60\n100/100 [==============================] - 7s 74ms/step - loss: 0.1681 - acc: 0.9425 - val_loss: 0.1263 - val_acc: 0.9563\nEpoch 17/60\n100/100 [==============================] - 6s 60ms/step - loss: 0.1323 - acc: 0.9563 - val_loss: 0.1336 - val_acc: 0.9573\nEpoch 18/60\n100/100 [==============================] - 6s 65ms/step - loss: 0.1529 - acc: 0.9475 - val_loss: 0.1441 - val_acc: 0.9458\nEpoch 19/60\n100/100 [==============================] - 6s 59ms/step - loss: 0.1172 - acc: 0.9553 - val_loss: 0.1133 - val_acc: 0.9531\nEpoch 20/60\n100/100 [==============================] - 6s 58ms/step - loss: 0.1312 - acc: 0.9534 - val_loss: 0.0965 - val_acc: 0.9667\nEpoch 21/60\n100/100 [==============================] - 6s 59ms/step - loss: 0.1073 - acc: 0.9594 - val_loss: 0.1282 - val_acc: 0.9573\nEpoch 22/60\n100/100 [==============================] - 7s 65ms/step - loss: 0.1148 - acc: 0.9569 - val_loss: 0.1069 - val_acc: 0.9510\nEpoch 23/60\n100/100 [==============================] - 7s 69ms/step - loss: 0.1196 - acc: 0.9556 - val_loss: 0.1182 - val_acc: 0.9531\nEpoch 24/60\n100/100 [==============================] - 6s 62ms/step - loss: 0.1166 - acc: 0.9578 - val_loss: 0.1053 - val_acc: 0.9615\nEpoch 25/60\n100/100 [==============================] - 7s 66ms/step - loss: 0.1175 - acc: 0.9572 - val_loss: 0.0868 - val_acc: 0.9667\nEpoch 26/60\n100/100 [==============================] - 6s 58ms/step - loss: 0.1134 - acc: 0.9588 - val_loss: 0.0989 - val_acc: 0.9688\nEpoch 27/60\n100/100 [==============================] - 6s 59ms/step - loss: 0.1170 - acc: 0.9556 - val_loss: 0.0941 - val_acc: 0.9677\nEpoch 28/60\n100/100 [==============================] - 6s 58ms/step - loss: 0.1172 - acc: 0.9525 - val_loss: 0.0869 - val_acc: 0.9708\nEpoch 29/60\n100/100 [==============================] - 6s 58ms/step - loss: 0.1080 - acc: 0.9609 - val_loss: 0.0942 - val_acc: 0.9698\nEpoch 30/60\n100/100 [==============================] - 6s 59ms/step - loss: 0.0840 - acc: 0.9700 - val_loss: 0.0782 - val_acc: 0.9708\nEpoch 31/60\n100/100 [==============================] - 6s 57ms/step - loss: 0.1059 - acc: 0.9603 - val_loss: 0.0979 - val_acc: 0.9635\nEpoch 32/60\n100/100 [==============================] - 6s 56ms/step - loss: 0.1024 - acc: 0.9659 - val_loss: 0.0966 - val_acc: 0.9583\nEpoch 33/60\n100/100 [==============================] - 6s 60ms/step - loss: 0.1096 - acc: 0.9597 - val_loss: 0.1019 - val_acc: 0.9656\nEpoch 34/60\n100/100 [==============================] - 6s 60ms/step - loss: 0.1064 - acc: 0.9613 - val_loss: 0.0950 - val_acc: 0.9708\nEpoch 35/60\n100/100 [==============================] - 6s 58ms/step - loss: 0.0853 - acc: 0.9706 - val_loss: 0.0747 - val_acc: 0.9760\nEpoch 36/60\n100/100 [==============================] - 6s 57ms/step - loss: 0.0858 - acc: 0.9681 - val_loss: 0.1046 - val_acc: 0.9656\nEpoch 37/60\n100/100 [==============================] - 6s 58ms/step - loss: 0.0914 - acc: 0.9659 - val_loss: 0.0862 - val_acc: 0.9646\nEpoch 38/60\n100/100 [==============================] - 6s 58ms/step - loss: 0.0680 - acc: 0.9759 - val_loss: 0.1035 - val_acc: 0.9667\nEpoch 39/60\n100/100 [==============================] - 6s 58ms/step - loss: 0.0802 - acc: 0.9700 - val_loss: 0.1106 - val_acc: 0.9563\nEpoch 40/60\n100/100 [==============================] - 6s 58ms/step - loss: 0.0947 - acc: 0.9659 - val_loss: 0.0988 - val_acc: 0.9656\nEpoch 41/60\n100/100 [==============================] - 6s 58ms/step - loss: 0.1110 - acc: 0.9606 - val_loss: 0.1036 - val_acc: 0.9635\nEpoch 42/60\n100/100 [==============================] - 6s 58ms/step - loss: 0.0887 - acc: 0.9703 - val_loss: 0.0821 - val_acc: 0.9688\nEpoch 43/60\n100/100 [==============================] - 6s 58ms/step - loss: 0.0972 - acc: 0.9641 - val_loss: 0.1012 - val_acc: 0.9625\nEpoch 44/60\n100/100 [==============================] - 6s 58ms/step - loss: 0.0660 - acc: 0.9756 - val_loss: 0.0907 - val_acc: 0.9646\nEpoch 45/60\n100/100 [==============================] - 6s 58ms/step - loss: 0.0814 - acc: 0.9725 - val_loss: 0.0695 - val_acc: 0.9750\nEpoch 46/60\n100/100 [==============================] - 6s 57ms/step - loss: 0.0689 - acc: 0.9769 - val_loss: 0.1047 - val_acc: 0.9635\nEpoch 47/60\n100/100 [==============================] - 6s 57ms/step - loss: 0.0807 - acc: 0.9716 - val_loss: 0.0852 - val_acc: 0.9635\nEpoch 48/60\n100/100 [==============================] - 6s 58ms/step - loss: 0.0850 - acc: 0.9684 - val_loss: 0.0767 - val_acc: 0.9698\nEpoch 49/60\n100/100 [==============================] - 6s 58ms/step - loss: 0.0815 - acc: 0.9694 - val_loss: 0.0759 - val_acc: 0.9729\nEpoch 50/60\n100/100 [==============================] - 6s 58ms/step - loss: 0.0796 - acc: 0.9709 - val_loss: 0.1104 - val_acc: 0.9625\nEpoch 51/60\n100/100 [==============================] - 6s 58ms/step - loss: 0.0809 - acc: 0.9734 - val_loss: 0.0814 - val_acc: 0.9656\nEpoch 52/60\n100/100 [==============================] - 6s 58ms/step - loss: 0.0809 - acc: 0.9703 - val_loss: 0.0795 - val_acc: 0.9667\nEpoch 53/60\n100/100 [==============================] - 6s 58ms/step - loss: 0.0802 - acc: 0.9694 - val_loss: 0.0837 - val_acc: 0.9656\nEpoch 54/60\n100/100 [==============================] - 6s 62ms/step - loss: 0.0778 - acc: 0.9694 - val_loss: 0.0551 - val_acc: 0.9781\nEpoch 55/60\n100/100 [==============================] - 6s 58ms/step - loss: 0.0514 - acc: 0.9822 - val_loss: 0.0552 - val_acc: 0.9792\nEpoch 56/60\n100/100 [==============================] - 6s 58ms/step - loss: 0.0734 - acc: 0.9731 - val_loss: 0.0762 - val_acc: 0.9729\nEpoch 57/60\n100/100 [==============================] - 6s 58ms/step - loss: 0.0787 - acc: 0.9741 - val_loss: 0.0858 - val_acc: 0.9604\nEpoch 58/60\n100/100 [==============================] - 6s 58ms/step - loss: 0.0834 - acc: 0.9694 - val_loss: 0.0783 - val_acc: 0.9667\nEpoch 59/60\n100/100 [==============================] - 6s 57ms/step - loss: 0.0769 - acc: 0.9712 - val_loss: 0.0702 - val_acc: 0.9719\nEpoch 60/60\n100/100 [==============================] - 6s 58ms/step - loss: 0.0629 - acc: 0.9778 - val_loss: 0.0719 - val_acc: 0.9708\n"
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=60,\n",
    "    validation_data=validate,\n",
    "    validation_steps=30,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "100/100 [==============================] - 9s 89ms/step - loss: 0.0905 - acc: 0.9691\n[0.09050730416085571, 0.9690625]\n"
    }
   ],
   "source": [
    "print(model.evaluate(test, steps=100))"
   ]
  }
 ]
}