{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## manual data augmentation\n",
    "\n",
    "In this notebook the code written to augmentate data is consolidated into a few lines of code.\n",
    "`src.utils` should not need any further explanation.\n",
    "\n",
    "The code is basically emulation the behavior of the keras image generator, but also accepts another parameter `repetitions`.\n",
    "The data is processed into the interim folder applying the modifications before training.\n",
    "Therefore the manipulations do not take place during training, but a time independent preprocessing phase.\n",
    "\n",
    "The images are copied to the `interim` directory first.\n",
    "After the data is fully distributed into `interim`, the data gets augmented \"inplace\", meaning we only work with the `interim` data and the result is a `interim` directory with all the augmented data (in this case 32000 images per class).\n",
    "\n",
    "`inline_augment_images` returns a list with dictionaries.\n",
    "These dictionaries contain all necessary information to create records in the upcoming cell.\n",
    "\n",
    "The parameters should be self explanatory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "import os\n",
    "from os import path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def augment_images_by_label(src_dir, target_dir, label_idx, target_size=(None, None),\n",
    "    repetitions=1, h_flip=False, v_flip=False, rotation_range=0, quantity=None):\n",
    "    \"\"\"Augments the images labelwise\n",
    "\n",
    "    Arguments:\n",
    "        src_dir: Where the (raw) images are taken from.\n",
    "        target_dir: Where the augmented images are going to be safed.\n",
    "        label: Label to add to the feature_description.\n",
    "        target_size: Size of the output image.\n",
    "            If at least one entry is None, the original size is used.\n",
    "        repetitions: How often should this run over the original dataset?\n",
    "        h_flip: Is it okay if the images are flipped horizontally?\n",
    "        v_flip: Is it okay if the images are flipped vertically?\n",
    "        rotation_range: In what range can the images be rotated (in degrees)?\n",
    "        quantity: How many images should be taken from the original dataset?\n",
    "            None means => all.\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    filenames =  list(filter(lambda x: x[-5:] == '.jpeg', os.listdir(src_dir)))\n",
    "    for filename in filenames[:quantity]:\n",
    "        image_path = path.join(src_dir, filename)\n",
    "        image = cv2.imread(image_path)\n",
    "        if h_flip:\n",
    "            image = cv2.flip(image, 0)\n",
    "        if v_flip:\n",
    "            image = cv2.flip(image, 1)\n",
    "        if None not in target_size:\n",
    "            image = cv2.resize(image, target_size)\n",
    "\n",
    "        angle = np.random.uniform(0.0, rotation_range)\n",
    "        rotmat = cv2.getRotationMatrix2D(tuple(np.divide(image.shape[:2], 2)), angle, 1.0)\n",
    "        image = cv2.warpAffine(image, rotmat, image.shape[:2])\n",
    "\n",
    "        os.makedirs(target_dir, exist_ok=True)\n",
    "        name = str(len(os.listdir(target_dir)))\n",
    "        \n",
    "        # the angle should be labeled between [0, 180)\n",
    "        angle = int(abs(h_flip*360-abs(v_flip*180-angle))) % 180\n",
    "        data_list.append({\n",
    "            'image_path': path.join(target_dir, name + '.jpeg'),\n",
    "            'label': [label_idx, angle],\n",
    "        })\n",
    "        cv2.imwrite(data_list[-1]['image_path'], image)\n",
    "\n",
    "    return data_list\n",
    "\n",
    "def augment_images(src_dir, target_dir, repetitions=1, *args, **kwargs):\n",
    "    \"\"\"Augments images in src_dir and saves them to target_dir.\n",
    "\n",
    "    Arguments:\n",
    "        src_dir: Where the (raw) images are taken from.\n",
    "        target_dir: Where the augmented images are going to be safed.\n",
    "        repetitions: How often should this run over the original dataset?\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "    data_list = []\n",
    "\n",
    "    for label_idx, label in enumerate(os.listdir(src_dir)):\n",
    "        actual_src_dir = path.join(src_dir, label)\n",
    "        actual_target_dir = path.join(target_dir, label)\n",
    "\n",
    "        for i in tqdm(range(repetitions)):\n",
    "            data_list += augment_images_by_label(\n",
    "                actual_src_dir, actual_target_dir, label_idx, *args, **kwargs)\n",
    "\n",
    "    np.random.shuffle(data_list)\n",
    "\n",
    "    with open(path.join(target_dir, 'config.json'), 'w') as config:\n",
    "        json.dump(data_list, config)\n",
    "\n",
    "    return data_list\n",
    "\n",
    "def inline_augment_images(directory, *args, **kwargs):\n",
    "    \"\"\"Augments images inplace (source and target directory are the same).\n",
    "\n",
    "    Arguments:\n",
    "        directory: source and target directory.\n",
    "\n",
    "    An intermediate 'directory_tmp' is created.\n",
    "    It is removed after the operation has finished.\n",
    "    \"\"\"\n",
    "\n",
    "    tmp = directory + '_tmp'\n",
    "    os.rename(directory, tmp)\n",
    "    data_list = augment_images(tmp, directory, *args, **kwargs)\n",
    "\n",
    "    try:\n",
    "        shutil.rmtree(tmp, ignore_errors=True)\n",
    "    except OSError as e:\n",
    "        print (\"Error: %s - %s.\" % (e.filename, e.strerror))\n",
    "\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "100%|██████████| 32/32 [13:10<00:00, 24.70s/it]\n100%|██████████| 32/32 [14:11<00:00, 26.62s/it]\n100%|██████████| 32/32 [14:29<00:00, 27.16s/it]\n100%|██████████| 1/1 [00:01<00:00,  1.48s/it]\n100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n100%|██████████| 1/1 [00:01<00:00,  1.10s/it]\n100%|██████████| 1/1 [00:01<00:00,  1.08s/it]\n100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n"
    }
   ],
   "source": [
    "from src.utils import reset_and_distribute_data, encode_image_data_as_record\n",
    "\n",
    "raw = path.join('data', 'srp_raw_02')\n",
    "interim = path.join('data', 'interim')\n",
    "processed = path.join('data', 'processed')\n",
    "\n",
    "reset_and_distribute_data(raw, interim, [1000, 100, 100])\n",
    "shutil.rmtree(processed, ignore_errors=True)\n",
    "\n",
    "target_size=(32, 32)\n",
    "\n",
    "train_data_list = inline_augment_images(path.join(interim, 'train'),\n",
    "    repetitions=32, h_flip=True, v_flip=True, rotation_range=360, target_size=target_size)\n",
    "\n",
    "validate_data_list = inline_augment_images(path.join(interim, 'validate'), target_size=target_size)\n",
    "\n",
    "test_data_list = inline_augment_images(path.join(interim, 'test'), target_size=target_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "`encode_record` takes the previously described list, which is hardcoded in this instance as:\n",
    "```python\n",
    "feature = {\n",
    "    'image': # /path/to/image\n",
    "    'label': # [label_idx, angle]\n",
    "}\n",
    "```\n",
    "\n",
    "These features are then used to create protobufs.\n",
    "protobufs can be read by Tensorflow very efficient and with no overhead of decoding the data (the decoding takes place during the preprocessing here).\n",
    "\n",
    "This procedure also gives way more control over how the data is stored. For example the angle in this instance is saved, because maybe in the future it may be interesting to determine the angle of a linear node, where the data is way easier to generate by using only vertical lines (and the randomization is done by the augmentation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = os.listdir(raw)\n",
    "\n",
    "train_record    = path.join(processed, 'train.tfrecord')\n",
    "validate_record = path.join(processed, 'validate.tfrecord')\n",
    "test_record     = path.join(processed, 'test.tfrecord')\n",
    "\n",
    "encode_image_data_as_record(train_data_list, train_record)\n",
    "encode_image_data_as_record(validate_data_list, validate_record)\n",
    "encode_image_data_as_record(test_data_list, test_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to create data generators or iterators for the model which can read these tensorflow records."
   ]
  }
 ]
}