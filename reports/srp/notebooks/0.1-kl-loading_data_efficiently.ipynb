{"cells":[{"cell_type":"markdown","metadata":{},"outputs":[],"source":["## loading data for efficient training\n","\n","The generators used previously work fine, but are slow compared to other methods, as mentioned by the tensorflow team [here](https://www.tensorflow.org/tutorials/load_data/images#load_using_tfdata).\n","\n","Because the goal is to test a lot of different models on the data, speed is an important factor.\n","For this the tensorflow dataset API is explored here.\n","\n","Please note, that the data augmentation previously made possible by Keras' ImageDataGenerator class is removed and has to be applied manually to achieve the previously seen results."]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"data":{"text/plain":"['data\\\\processed\\\\train\\\\n',\n 'data\\\\processed\\\\validation\\\\n',\n 'data\\\\processed\\\\test\\\\n',\n 'data\\\\processed\\\\train\\\\o',\n 'data\\\\processed\\\\validation\\\\o',\n 'data\\\\processed\\\\test\\\\o',\n 'data\\\\processed\\\\train\\\\x',\n 'data\\\\processed\\\\validation\\\\x',\n 'data\\\\processed\\\\test\\\\x']"},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["from os.path import join\n","\n","raw = join('data', 'raw')\n","processed = join('data', 'processed')\n","\n","from src.training_env import reset_and_populate\n","\n","reset_and_populate(raw, processed, [400,0,100])"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","from os import sep\n","import pathlib\n","\n","def create_dataset(data_dir, batch_size=32, shuffle_buffer_size=1000):\n","        def get_label(file_path):\n","                parts = tf.strings.split(file_path, sep)\n","                return parts[-2] == labels\n","\n","        def decode_img(img):\n","                img = tf.image.decode_png(img, channels=1)\n","                img = tf.image.convert_image_dtype(img, tf.float32)\n","                return tf.image.resize(img, [32, 32])\n","\n","        def process_path(file_path):\n","                label = get_label(file_path)\n","                img = tf.io.read_file(file_path)\n","                img = decode_img(img)\n","                return img, label\n","\n","        data_dir = pathlib.Path(join(processed, data_dir))\n","\n","        labels = np.array([item.name for item in data_dir.glob('*')])\n","\n","        autotune = tf.data.experimental.AUTOTUNE\n","\n","        ds = (tf.data.Dataset.list_files(str(data_dir/'*/*'))\n","                .map(process_path, num_parallel_calls=autotune)\n","                .cache()\n","                .shuffle(shuffle_buffer_size)\n","                .repeat()\n","                .batch(batch_size)\n","                .prefetch(buffer_size=autotune))\n","        return iter(ds)\n","\n","train_generator = create_dataset('train', 20)\n","test_generator = create_dataset('test', 10)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nflatten (Flatten)            (None, 1024)              0         \n_________________________________________________________________\ndense (Dense)                (None, 32)                32800     \n_________________________________________________________________\ndense_1 (Dense)              (None, 32)                1056      \n_________________________________________________________________\ndense_2 (Dense)              (None, 3)                 99        \n=================================================================\nTotal params: 33,955\nTrainable params: 33,955\nNon-trainable params: 0\n_________________________________________________________________\n"}],"source":["from tensorflow.keras import layers\n","from tensorflow.keras import models\n","\n","model = models.Sequential()\n","model.add(layers.Flatten(input_shape=(32, 32, 1)))\n","model.add(layers.Dense(32,'relu'))\n","model.add(layers.Dense(32,'relu'))\n","model.add(layers.Dense(3, 'softmax'))\n","\n","model.summary()"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["from tensorflow.keras.optimizers import SGD, RMSprop\n","\n","optimizer = SGD(lr=0.005, momentum=0.9, nesterov=True)\n","\n","model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['acc'])"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Epoch 1/20\n20/20 [==============================] - 2s 92ms/step - loss: 1.1043 - acc: 0.3800\nEpoch 2/20\n20/20 [==============================] - 0s 24ms/step - loss: 1.1051 - acc: 0.3575\nEpoch 3/20\n20/20 [==============================] - 0s 24ms/step - loss: 1.0471 - acc: 0.4325\nEpoch 4/20\n20/20 [==============================] - 1s 25ms/step - loss: 0.9944 - acc: 0.5325\nEpoch 5/20\n20/20 [==============================] - 0s 24ms/step - loss: 0.9113 - acc: 0.6450\nEpoch 6/20\n20/20 [==============================] - 0s 22ms/step - loss: 0.8528 - acc: 0.7050\nEpoch 7/20\n20/20 [==============================] - 0s 24ms/step - loss: 0.7695 - acc: 0.7275\nEpoch 8/20\n20/20 [==============================] - 0s 24ms/step - loss: 0.7163 - acc: 0.7425\nEpoch 9/20\n20/20 [==============================] - 0s 24ms/step - loss: 0.7050 - acc: 0.7600\nEpoch 10/20\n20/20 [==============================] - 0s 24ms/step - loss: 0.6240 - acc: 0.7850\nEpoch 11/20\n20/20 [==============================] - 1s 25ms/step - loss: 0.6119 - acc: 0.7775\nEpoch 12/20\n20/20 [==============================] - 1s 33ms/step - loss: 0.4999 - acc: 0.8325\nEpoch 13/20\n20/20 [==============================] - 0s 24ms/step - loss: 0.5269 - acc: 0.8250\nEpoch 14/20\n20/20 [==============================] - 0s 24ms/step - loss: 0.5005 - acc: 0.8125\nEpoch 15/20\n20/20 [==============================] - 1s 26ms/step - loss: 0.4965 - acc: 0.8275\nEpoch 16/20\n20/20 [==============================] - 1s 27ms/step - loss: 0.4769 - acc: 0.8350\nEpoch 17/20\n20/20 [==============================] - 0s 23ms/step - loss: 0.3733 - acc: 0.8850\nEpoch 18/20\n20/20 [==============================] - 0s 24ms/step - loss: 0.4882 - acc: 0.8225\nEpoch 19/20\n20/20 [==============================] - 0s 24ms/step - loss: 0.4187 - acc: 0.8625\nEpoch 20/20\n20/20 [==============================] - 0s 24ms/step - loss: 0.4027 - acc: 0.8575\n"}],"source":["from tensorflow.keras.callbacks import TensorBoard\n","import numpy as np\n","from datetime import datetime\n","from os import mkdir\n","\n","log_dir = join('logs', 'srp01', datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\"))\n","\n","callbacks = [ TensorBoard(\n","    log_dir=log_dir,\n","    histogram_freq=1,\n","    embeddings_freq=1) ]\n","\n","history = model.fit_generator(\n","    train_generator,\n","    steps_per_epoch=20,\n","    epochs=20,\n","    callbacks=callbacks)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":"[0.7228875041007996, 0.7]"},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["model.evaluate_generator(test_generator, steps=10)"]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}