{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load images from record\n",
    "\n",
    "Herein the data is to be load from TFRecords instead of the system directory.\n",
    "\n",
    "`inline_augment_images` takes the images in the provided directory and augments them in the directory, removing the old files of the `interim` directory.\n",
    "\n",
    "`augment_images` also returns a `list` of `dictionaries` which contain information about the images.\n",
    "This allows for an arbitrary amount of labels saved in the image to be saved without parsing the name of the file or similar.\n",
    "\n",
    "`encode_record` takes the respective `data_list` and creates TFRecords which are then load later.\n",
    "\n",
    "This methodology promises to be faster because necessary preprocessing like augmentation and decoding of the image is already done.\n",
    "\n",
    "Each loaded example of the record is a tensor ready to be put into the training algorithm, with parallel calls and prefetching of data for future steps embedded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "import os\n",
    "from os import path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def augment_images_by_label(src_dir, target_dir, label_idx, target_size=(None, None),\n",
    "    repetitions=1, h_flip=False, v_flip=False, rotation_range=0, quantity=None):\n",
    "    \"\"\"Augments the images labelwise\n",
    "\n",
    "    Arguments:\n",
    "        src_dir: Where the (raw) images are taken from.\n",
    "        target_dir: Where the augmented images are going to be safed.\n",
    "        label: Label to add to the feature_description.\n",
    "        target_size: Size of the output image.\n",
    "            If at least one entry is None, the original size is used.\n",
    "        repetitions: How often should this run over the original dataset?\n",
    "        h_flip: Is it okay if the images are flipped horizontally?\n",
    "        v_flip: Is it okay if the images are flipped vertically?\n",
    "        rotation_range: In what range can the images be rotated (in degrees)?\n",
    "        quantity: How many images should be taken from the original dataset?\n",
    "            None means => all.\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    filenames =  list(filter(lambda x: x[-5:] == '.jpeg', os.listdir(src_dir)))\n",
    "    for filename in filenames[:quantity]:\n",
    "        image_path = path.join(src_dir, filename)\n",
    "        image = cv2.imread(image_path)\n",
    "        if h_flip:\n",
    "            image = cv2.flip(image, 0)\n",
    "        if v_flip:\n",
    "            image = cv2.flip(image, 1)\n",
    "        if None not in target_size:\n",
    "            image = cv2.resize(image, target_size)\n",
    "\n",
    "        angle = np.random.uniform(0.0, rotation_range)\n",
    "        rotmat = cv2.getRotationMatrix2D(tuple(np.divide(image.shape[:2], 2)), angle, 1.0)\n",
    "        image = cv2.warpAffine(image, rotmat, image.shape[:2])\n",
    "\n",
    "        os.makedirs(target_dir, exist_ok=True)\n",
    "        name = str(len(os.listdir(target_dir)))\n",
    "        \n",
    "        # the angle should be labeled between [0, 180)\n",
    "        angle = int(abs(h_flip*360-abs(v_flip*180-angle))) % 180\n",
    "        data_list.append({\n",
    "            'image_path': path.join(target_dir, name + '.jpeg'),\n",
    "            'label': [label_idx, angle],\n",
    "        })\n",
    "        cv2.imwrite(data_list[-1]['image_path'], image)\n",
    "\n",
    "    return data_list\n",
    "\n",
    "def augment_images(src_dir, target_dir, repetitions=1, *args, **kwargs):\n",
    "    \"\"\"Augments images in src_dir and saves them to target_dir.\n",
    "\n",
    "    Arguments:\n",
    "        src_dir: Where the (raw) images are taken from.\n",
    "        target_dir: Where the augmented images are going to be safed.\n",
    "        repetitions: How often should this run over the original dataset?\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "    data_list = []\n",
    "\n",
    "    for label_idx, label in enumerate(os.listdir(src_dir)):\n",
    "        actual_src_dir = path.join(src_dir, label)\n",
    "        actual_target_dir = path.join(target_dir, label)\n",
    "\n",
    "        for i in tqdm(range(repetitions)):\n",
    "            data_list += augment_images_by_label(\n",
    "                actual_src_dir, actual_target_dir, label_idx, *args, **kwargs)\n",
    "\n",
    "    np.random.shuffle(data_list)\n",
    "\n",
    "    with open(path.join(target_dir, 'config.json'), 'w') as config:\n",
    "        json.dump(data_list, config)\n",
    "\n",
    "    return data_list\n",
    "\n",
    "def inline_augment_images(directory, *args, **kwargs):\n",
    "    \"\"\"Augments images inplace (source and target directory are the same).\n",
    "\n",
    "    Arguments:\n",
    "        directory: source and target directory.\n",
    "\n",
    "    An intermediate 'directory_tmp' is created.\n",
    "    It is removed after the operation has finished.\n",
    "    \"\"\"\n",
    "\n",
    "    tmp = directory + '_tmp'\n",
    "    os.rename(directory, tmp)\n",
    "    data_list = augment_images(tmp, directory, *args, **kwargs)\n",
    "\n",
    "    try:\n",
    "        shutil.rmtree(tmp, ignore_errors=True)\n",
    "    except OSError as e:\n",
    "        print (\"Error: %s - %s.\" % (e.filename, e.strerror))\n",
    "\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "100%|██████████| 1/1 [00:04<00:00,  4.41s/it]\n100%|██████████| 1/1 [00:04<00:00,  4.72s/it]\n100%|██████████| 1/1 [00:04<00:00,  4.83s/it]\n100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n100%|██████████| 1/1 [00:01<00:00,  1.07s/it]\n"
    }
   ],
   "source": [
    "raw = path.join('data', 'raw')\n",
    "interim = path.join('data', 'interim')\n",
    "processed = path.join('data', 'processed')\n",
    "\n",
    "from src.utils import encode_image_data_as_record, reset_and_distribute_data\n",
    "\n",
    "reset_and_distribute_data(raw, interim, [400,100,0])\n",
    "\n",
    "train_data_list     = inline_augment_images(path.join(interim, 'train'), target_size=(32, 32))\n",
    "validate_data_list = inline_augment_images(path.join(interim, 'validate'), target_size=(32, 32))\n",
    "\n",
    "\n",
    "labels = os.listdir(raw)\n",
    "\n",
    "train_record    = path.join(processed, 'train.tfrecord')\n",
    "validate_record = path.join(processed, 'validate.tfrecord')\n",
    "\n",
    "encode_image_data_as_record(train_data_list, train_record)\n",
    "encode_image_data_as_record(validate_data_list, validate_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from src.utils import decode_image_record\n",
    "\n",
    "processed = path.join('data', 'processed')\n",
    "\n",
    "features = {\n",
    "    'image': tf.io.FixedLenFeature([], tf.string),\n",
    "    'label': tf.io.FixedLenFeature([2], tf.int64)\n",
    "}\n",
    "shape = (32, 32, 1)\n",
    "\n",
    "def decoder(example):\n",
    "    feature = tf.io.parse_single_example(example, features)\n",
    "    image = tf.io.parse_tensor(feature['image'], tf.float32)\n",
    "    image.set_shape(shape)\n",
    "    # We only want the 'label_idx'. Not the 'angle'.\n",
    "    label = feature['label'][0]\n",
    "\n",
    "    return [image, label]\n",
    "\n",
    "\n",
    "train_dataset = decode_image_record(path.join(processed, 'train.tfrecord'), decoder, batch_size=32)\n",
    "validation_dataset = decode_image_record(path.join(processed, 'validate.tfrecord'), decoder, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Flatten(input_shape=(32, 32, 1)))\n",
    "model.add(layers.Dense(32,'relu'))\n",
    "model.add(layers.Dense(32,'relu'))\n",
    "model.add(layers.Dense(3, 'softmax'))\n",
    "\n",
    "optimizer = SGD(lr=0.005, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train for 20 steps\nEpoch 1/20\n20/20 [==============================] - 1s 33ms/step - loss: 1.0996 - acc: 0.3359\nEpoch 2/20\n20/20 [==============================] - 0s 6ms/step - loss: 1.0869 - acc: 0.4219\nEpoch 3/20\n20/20 [==============================] - 0s 6ms/step - loss: 1.0412 - acc: 0.4859\nEpoch 4/20\n20/20 [==============================] - 0s 6ms/step - loss: 0.9783 - acc: 0.5953\nEpoch 5/20\n20/20 [==============================] - 0s 6ms/step - loss: 0.9363 - acc: 0.5938\nEpoch 6/20\n20/20 [==============================] - 0s 5ms/step - loss: 0.8783 - acc: 0.6766\nEpoch 7/20\n20/20 [==============================] - 0s 6ms/step - loss: 0.8053 - acc: 0.7156\nEpoch 8/20\n20/20 [==============================] - 0s 6ms/step - loss: 0.7643 - acc: 0.7469\nEpoch 9/20\n20/20 [==============================] - 0s 5ms/step - loss: 0.6859 - acc: 0.7781\nEpoch 10/20\n20/20 [==============================] - 0s 6ms/step - loss: 0.6493 - acc: 0.8125\nEpoch 11/20\n20/20 [==============================] - 0s 6ms/step - loss: 0.6391 - acc: 0.7812\nEpoch 12/20\n20/20 [==============================] - 0s 9ms/step - loss: 0.5539 - acc: 0.8375\nEpoch 13/20\n20/20 [==============================] - 0s 8ms/step - loss: 0.5164 - acc: 0.8344\nEpoch 14/20\n20/20 [==============================] - 0s 9ms/step - loss: 0.4864 - acc: 0.8516\nEpoch 15/20\n20/20 [==============================] - 0s 8ms/step - loss: 0.4722 - acc: 0.8547\nEpoch 16/20\n20/20 [==============================] - 0s 8ms/step - loss: 0.4554 - acc: 0.8516\nEpoch 17/20\n20/20 [==============================] - 0s 8ms/step - loss: 0.4246 - acc: 0.8609\nEpoch 18/20\n20/20 [==============================] - 0s 6ms/step - loss: 0.4022 - acc: 0.8719\nEpoch 19/20\n20/20 [==============================] - 0s 6ms/step - loss: 0.4129 - acc: 0.8516\nEpoch 20/20\n20/20 [==============================] - 0s 6ms/step - loss: 0.3862 - acc: 0.8562\n"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from os import mkdir\n",
    "\n",
    "log_dir = path.join('logs', 'srp16', datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\"))\n",
    "\n",
    "callbacks = [ TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1,\n",
    "    embeddings_freq=1) ]\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=20,\n",
    "    epochs=20,\n",
    "    callbacks=callbacks)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}