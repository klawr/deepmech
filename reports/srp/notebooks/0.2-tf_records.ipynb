{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load images from record\n",
    "\n",
    "Herein the data is to be load from TFRecords instead of the system directory.\n",
    "\n",
    "`inline_augment_images` takes the images in the provided directory and augments them in the directory, removing the old files of the `interim` directory.\n",
    "\n",
    "`augment_images` also returns a `list` of `dictionaries` which contain information about the images.\n",
    "This allows for an arbitrary amount of labels saved in the image to be saved without parsing the name of the file or similar.\n",
    "\n",
    "`encode_record` takes the respective `data_list` and creates TFRecords which are then load later.\n",
    "\n",
    "This methodology promises to be faster because necessary preprocessing like augmentation and decoding of the image is already done.\n",
    "\n",
    "Each loaded example of the record is a tensor ready to be put into the training algorithm, with parallel calls and prefetching of data for future steps embedded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "\n",
    "raw = join('data', 'raw')\n",
    "interim = join('data', 'interim')\n",
    "processed = join('data', 'processed')\n",
    "\n",
    "from src.utils import reset_and_distribute_data\n",
    "\n",
    "reset_and_distribute_data(raw, interim, [400,100,0])\n",
    "\n",
    "from src.image_handling import encode_record, inline_augment_images\n",
    "\n",
    "train_images = inline_augment_images(join(interim, 'train'), target_size=(32, 32))\n",
    "validation_images = inline_augment_images(join(interim, 'validation'), target_size=(32, 32))\n",
    "\n",
    "encode_record(train_images, ['n', 'o', 'x'], processed, 'train')\n",
    "encode_record(validation_images, ['n', 'o', 'x'], processed, 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "example_featue_description = { \n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'label': tf.io.FixedLenFeature([], tf.int64)\n",
    "}\n",
    "\n",
    "def decode_record(record_path, batch_size, shuffle_buffer_size=1000):\n",
    "        def decode_example(example):\n",
    "                features = tf.io.parse_single_example(example, example_featue_description)\n",
    "                image = tf.io.parse_tensor(features['image'], tf.float32)\n",
    "                image.set_shape([32, 32, 1])\n",
    "                label = features['label']\n",
    "\n",
    "                return image, label\n",
    "\n",
    "        autotune = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "        data = (tf.data.TFRecordDataset(record_path)\n",
    "                .map(decode_example, num_parallel_calls=autotune)\n",
    "                .cache()\n",
    "                .shuffle(shuffle_buffer_size)\n",
    "                .repeat()\n",
    "                .batch(batch_size)\n",
    "                .prefetch(buffer_size=autotune))\n",
    "        return data\n",
    "\n",
    "train_dataset = decode_record(join(processed, 'train.tfrecord'), 32)\n",
    "validation_dataset = decode_record(join(processed, 'validation.tfrecord'), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Flatten(input_shape=(32, 32, 1)))\n",
    "model.add(layers.Dense(32,'relu'))\n",
    "model.add(layers.Dense(32,'relu'))\n",
    "model.add(layers.Dense(3, 'softmax'))\n",
    "\n",
    "optimizer = SGD(lr=0.005, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train for 20 steps\nEpoch 1/20\n 1/20 [>.............................] - ETA: 28s - loss: 1.1747 - acc: 0.2812WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.118002). Check your callbacks.\n20/20 [==============================] - 2s 82ms/step - loss: 1.0864 - acc: 0.3609\nEpoch 2/20\n20/20 [==============================] - 0s 7ms/step - loss: 1.0394 - acc: 0.4656\nEpoch 3/20\n20/20 [==============================] - 0s 7ms/step - loss: 0.9611 - acc: 0.6000\nEpoch 4/20\n20/20 [==============================] - 0s 7ms/step - loss: 0.9030 - acc: 0.6172\nEpoch 5/20\n20/20 [==============================] - 0s 7ms/step - loss: 0.8220 - acc: 0.7031\nEpoch 6/20\n20/20 [==============================] - 0s 7ms/step - loss: 0.7787 - acc: 0.7234\nEpoch 7/20\n20/20 [==============================] - 0s 7ms/step - loss: 0.6962 - acc: 0.7672\nEpoch 8/20\n20/20 [==============================] - 0s 7ms/step - loss: 0.6403 - acc: 0.7859\nEpoch 9/20\n20/20 [==============================] - 0s 6ms/step - loss: 0.5849 - acc: 0.8094\nEpoch 10/20\n20/20 [==============================] - 0s 6ms/step - loss: 0.5518 - acc: 0.8359\nEpoch 11/20\n20/20 [==============================] - 0s 6ms/step - loss: 0.5156 - acc: 0.8531\nEpoch 12/20\n20/20 [==============================] - 0s 7ms/step - loss: 0.4671 - acc: 0.8531\nEpoch 13/20\n20/20 [==============================] - 0s 6ms/step - loss: 0.4703 - acc: 0.8531\nEpoch 14/20\n20/20 [==============================] - 0s 7ms/step - loss: 0.4586 - acc: 0.8531\nEpoch 15/20\n20/20 [==============================] - 0s 7ms/step - loss: 0.4275 - acc: 0.8719\nEpoch 16/20\n20/20 [==============================] - 0s 7ms/step - loss: 0.3980 - acc: 0.8766\nEpoch 17/20\n20/20 [==============================] - 0s 7ms/step - loss: 0.3758 - acc: 0.8984\nEpoch 18/20\n20/20 [==============================] - 0s 7ms/step - loss: 0.3792 - acc: 0.8813\nEpoch 19/20\n20/20 [==============================] - 0s 7ms/step - loss: 0.3573 - acc: 0.9031\nEpoch 20/20\n20/20 [==============================] - 0s 7ms/step - loss: 0.3875 - acc: 0.8719\n"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from os import mkdir\n",
    "\n",
    "log_dir = join('logs', 'srp16', datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\"))\n",
    "mkdir(log_dir)\n",
    "\n",
    "callbacks = [ TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1,\n",
    "    embeddings_freq=1) ]\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=20,\n",
    "    epochs=20,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}