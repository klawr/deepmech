{"cells":[{"cell_type":"markdown","metadata":{},"outputs":[],"source":["## convolutional layers\n","\n","convolutional layers are very often used in image recognition tasks for machine learning.\n","In this notebook the dense layers are replaced by convolutional layers to test this claim."]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"data":{"text/plain":"['data\\\\processed\\\\train\\\\n',\n 'data\\\\processed\\\\validation\\\\n',\n 'data\\\\processed\\\\test\\\\n',\n 'data\\\\processed\\\\train\\\\o',\n 'data\\\\processed\\\\validation\\\\o',\n 'data\\\\processed\\\\test\\\\o',\n 'data\\\\processed\\\\train\\\\x',\n 'data\\\\processed\\\\validation\\\\x',\n 'data\\\\processed\\\\test\\\\x']"},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["from os.path import join\n","\n","raw = join('data', 'raw')\n","processed = join('data', 'processed')\n","\n","from src.training_env import reset_and_populate\n","\n","reset_and_populate(raw, processed, [400,0,100])"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Found 1200 images belonging to 3 classes.\nFound 300 images belonging to 3 classes.\n"}],"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","def create_generator(data_dir, batch_size, datagen):\n","    full_path = join(processed, data_dir)\n","    return datagen.flow_from_directory(\n","        full_path,\n","        target_size=(32, 32),\n","        color_mode='grayscale',\n","        batch_size=batch_size,\n","        class_mode='binary')\n","\n","train_datagen = ImageDataGenerator(\n","        rescale = 1./255,\n","        rotation_range=360,\n","        horizontal_flip=True,\n","        vertical_flip=True)\n","\n","test_datagen = ImageDataGenerator(rescale = 1./255)\n","\n","train_generator = create_generator('train', 20, train_datagen)\n","test_generator = create_generator('test', 10, test_datagen)"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["In this notebook two 2-dimensional convolutional layers are used.\n","The padding is set to 'same' to keep the output shape the same.\n","The filter size is set to eight for both layers and the kernel size is four by four.\n","\n","These hyper-parameters are again set by a little manual testing to provide a somewhat reasonable result.\n","\n","The number of parameters is smaller than the dense layer (the previous models had 33955 parameter)."]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 32, 32, 8)         136       \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 32, 32, 8)         1032      \n_________________________________________________________________\nflatten (Flatten)            (None, 8192)              0         \n_________________________________________________________________\ndense (Dense)                (None, 3)                 24579     \n=================================================================\nTotal params: 25,747\nTrainable params: 25,747\nNon-trainable params: 0\n_________________________________________________________________\n"}],"source":["from tensorflow.keras import layers\n","from tensorflow.keras import models\n","\n","model = models.Sequential()\n","model.add(layers.Conv2D(8, (4,4), activation='relu', padding='same', input_shape=(32, 32, 1)))\n","model.add(layers.Conv2D(8, (4,4), activation='relu', padding='same'))\n","model.add(layers.Flatten())\n","model.add(layers.Dense(3, 'softmax'))\n","\n","model.summary()"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["from tensorflow.keras.optimizers import SGD\n","\n","optimizer = SGD(lr=0.003, momentum=0.9, nesterov=True)\n","\n","model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['acc'])"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Epoch 1/20\n 1/20 [>.............................] - ETA: 29s - loss: 1.1042 - acc: 0.5000WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.132000). Check your callbacks.\n20/20 [==============================] - 3s 127ms/step - loss: 1.1126 - acc: 0.3325\nEpoch 2/20\n20/20 [==============================] - 2s 78ms/step - loss: 1.0889 - acc: 0.4000\nEpoch 3/20\n20/20 [==============================] - 2s 80ms/step - loss: 1.0622 - acc: 0.4800\nEpoch 4/20\n20/20 [==============================] - 1s 67ms/step - loss: 1.0377 - acc: 0.5075\nEpoch 5/20\n20/20 [==============================] - 1s 68ms/step - loss: 0.9722 - acc: 0.6500\nEpoch 6/20\n20/20 [==============================] - 1s 65ms/step - loss: 0.9004 - acc: 0.6825\nEpoch 7/20\n20/20 [==============================] - 2s 76ms/step - loss: 0.8367 - acc: 0.6750\nEpoch 8/20\n20/20 [==============================] - 1s 70ms/step - loss: 0.6837 - acc: 0.7525\nEpoch 9/20\n20/20 [==============================] - 1s 74ms/step - loss: 0.6896 - acc: 0.7425\nEpoch 10/20\n20/20 [==============================] - 1s 72ms/step - loss: 0.6105 - acc: 0.7350\nEpoch 11/20\n20/20 [==============================] - 1s 74ms/step - loss: 0.5550 - acc: 0.7775\nEpoch 12/20\n20/20 [==============================] - 1s 67ms/step - loss: 0.5350 - acc: 0.8000\nEpoch 13/20\n20/20 [==============================] - 2s 75ms/step - loss: 0.4576 - acc: 0.8075\nEpoch 14/20\n20/20 [==============================] - 1s 69ms/step - loss: 0.3873 - acc: 0.8650\nEpoch 15/20\n20/20 [==============================] - 1s 66ms/step - loss: 0.5770 - acc: 0.7850\nEpoch 16/20\n20/20 [==============================] - 1s 69ms/step - loss: 0.4856 - acc: 0.8250\nEpoch 17/20\n20/20 [==============================] - 1s 75ms/step - loss: 0.4117 - acc: 0.8650\nEpoch 18/20\n20/20 [==============================] - 1s 69ms/step - loss: 0.3393 - acc: 0.8800\nEpoch 19/20\n20/20 [==============================] - 1s 69ms/step - loss: 0.4812 - acc: 0.8125\nEpoch 20/20\n20/20 [==============================] - 1s 75ms/step - loss: 0.4187 - acc: 0.8500\n"}],"source":["from tensorflow.keras.callbacks import TensorBoard\n","import numpy as np\n","from datetime import datetime\n","from os import mkdir\n","\n","log_dir = join('logs', 'srp64', datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\"))\n","mkdir(log_dir)\n","\n","from src.training_env import reset\n","reset(log_dir)\n","\n","callbacks = [ TensorBoard(\n","    log_dir=log_dir,\n","    histogram_freq=1,\n","    embeddings_freq=1) ]\n","\n","history = model.fit_generator(\n","    train_generator,\n","    steps_per_epoch=20,\n","    epochs=20,\n","    callbacks=callbacks)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":"[0.44487083454926807, 0.85333335]"},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["model.evaluate_generator(test_generator)"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["The resulting model is smaller than the previous models (295kb to 232kb) and is more accurate with a lower loss. Therefore it seems that convolutional layer are indeed superior then simple dense layer for image recognition."]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["model_path = join('models', 'devel', 'srp64.h5')\n","model.save(model_path)"]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3},"version":"3.7.4"},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}