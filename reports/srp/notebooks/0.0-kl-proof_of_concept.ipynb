{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to start with a simple experiment, which shows that the concept is working at all.\n",
    "\n",
    "Target is to train a model to differentiate links and bases from non-fitting drawings. For this task a dataset consisting of about 500 examples each was created.\n",
    "I want to go through 5 different steps to show, that the model can differentiate *non-links* from *links*. Then the same algortithm is used to determine *bases*.\n",
    "\n",
    "This is the first try in a series of steps taken to create a neural network to identify fourbar linkages from sketches and map them to their digital counterparts.\n",
    "\n",
    "The steps taken are as follows:\n",
    " 1. Acquire data from local harddrive.\n",
    " 2. Prepare data by creating tensors of image, label pairs.\n",
    " 3. Create a simple CNN to classify \"links\" from \"non-hits\" (*o*'s from *n*'s).\n",
    " 4. Train model.\n",
    " 5. Evaluate results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1:\n",
    "Acquire Data and put them in proper directories to train on them.\n",
    "\n",
    "Data is stored in ../data/raw/{n, o, x} with either \"no match\", \"joints\" or \"bases\" respectively.\n",
    "\n",
    "Data is subdivided between *raw*, *interim* and *processed* directories. *interim* is not used here, since this simple proof of concept won't go into too much preprocessing of the data.\n",
    "\n",
    "The \"processed\" data is transfered into the appropriate directories at '../data/raw/{n, o, x}.\n",
    "        \n",
    "In these folders a subset of the *linkages* or *bases* and *non-hits* are placed to be used in training.\n",
    "\n",
    "To distribute the data accordingly, `src.training_env` provides useful functions. Namely:\n",
    "- create - To create a suitable skeleton for the processed data -> Returns path respectively.\n",
    "- populate - To populate those directories with data.\n",
    "- reset - To delete all files in processed for a clean restart.\n",
    "\n",
    "Combinations of those functions are provided for convenience (e.g. `reset_and_populate`)\n",
    "\n",
    "Because the *proof_of_concept* uses the `binary classifier` it only converges to a feasible result, if two classes are considered. Therefore we only observe *links* and *nohits* at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from os.path import join\n",
    "from src.training_env import create\n",
    "\n",
    "processed = join('..', 'data', 'processed')\n",
    "\n",
    "to_populate = [train_nohit, validate_nohit, test_nohit,\n",
    "               train_links, validate_links, test_links,\n",
    "               # train_bases, validate_bases, test_bases] \n",
    "              ] = create(['n', 'o'], processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However the raw data is never to be manipulated. Therefore the data gets subdivided into \"processed\" folder at '../data/processed/{train, validation, test}/{n, o, x}.\n",
    "\n",
    "The dataset consists of at least 500 entries each.\n",
    "To be exact, we take 500 images and distribute them about 60/20/20 into training, validation and test respectively.\n",
    "This means each set puts:\n",
    "300 entries into training.\n",
    "100 entries into validation.\n",
    "100 entries into test.\n",
    "\n",
    "To increase the number of data via augmentation is a subject for later investigation, if there is improvement to be expected.\n",
    "\n",
    "Since all data is named {0,1,2,3,4,5...}.jpeg inside their labelset, we can use this property to easily distribute the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.training_env import populate\n",
    "\n",
    "raw = join('..', 'data', 'raw')\n",
    "populate(raw, to_populate, [300,100,100], ['n', 'o'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "\n",
    "Preprocess data to be fit to be used. (Maybe data preprocessing is better to be done after model definition, because the model determines the input shape).\n",
    "\n",
    "The data has to be transformed into tensors which can be fed into the model.\n",
    "Four steps are suggested by the book (p.135):\n",
    " - Read the picture files.\n",
    " - Decode the JPEG content to RGB grids of pixels.\n",
    " - Convert these into floating-point tensors.\n",
    " - Rescale the pixel values (between 0 and 255) to the [0, 1] interval.\n",
    " \n",
    " At this instance, we can make use of generators. They are useful because not every image has to be loaded into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 600 images belonging to 2 classes.\n",
      "Found 200 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_dir = join(processed, 'train')\n",
    "validation_dir = join(processed, 'validation')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(512, 512),\n",
    "    batch_size=20,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(512, 512),\n",
    "    batch_size=20,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3\n",
    "\n",
    "Now a generic model for testing is created.\n",
    "\n",
    "Here the model from deep learning with python p. 134 is used.\n",
    "\n",
    "This should be reduced later an analyzed on my own. But for a quick proof of concept this should suffice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 510, 510, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 255, 255, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 253, 253, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 126, 126, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 124, 124, 128)     73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 62, 62, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 60, 60, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 115200)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               58982912  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 59,224,257\n",
      "Trainable params: 59,224,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(512, 512, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the model should be configured for training.\n",
    "Therefore optimizers are imported. For binary classification the loss function 'binary_crossentropy' and as optimizer 'RMSprop' is used.\n",
    "\n",
    "\n",
    "This is recommended by Francois Chollet. Why this is the case is a matter of further research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=RMSprop(lr=1e-4), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4\n",
    "\n",
    "Training the model is done via the \"fit\" method. for this the train_generator has to be used.\n",
    "\n",
    "Tensorboard should be used for visualisation. Therefore a log directory is created, with a suitable callback object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:From c:\\users\\me\\devel\\deepmech\\env\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1394: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 0.3283 - acc: 0.8710 - val_loss: 0.2826 - val_acc: 0.8950\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 65s 647ms/step - loss: 0.1334 - acc: 0.9495 - val_loss: 0.2766 - val_acc: 0.9200\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 65s 648ms/step - loss: 0.0923 - acc: 0.9735 - val_loss: 0.5096 - val_acc: 0.8850\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 64s 635ms/step - loss: 0.0631 - acc: 0.9795 - val_loss: 0.4513 - val_acc: 0.9150\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 63s 634ms/step - loss: 0.0487 - acc: 0.9855 - val_loss: 0.6510 - val_acc: 0.9150\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import numpy as np\n",
    "\n",
    "log_dir=(join('..', 'logs', 'srp00'))\n",
    "\n",
    "callbacks = [ TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1,\n",
    "    embeddings_freq=1) ]\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=5,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 5052), started 1:34:07 ago. (Use '!kill 5052' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e41c5328af50a978\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e41c5328af50a978\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {log_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5\n",
    "\n",
    "As you can see, the accuracy of the training data is improving with this approach. After only 1 epoch it is already at 87% accuracy, but the validation data stays around 90% accuracy for all epochs.\n",
    "\n",
    "This is a clear indicator for overfitting TODO *(look at coursera-ml-class to get the image of the opening loss scissor)*\n",
    "\n",
    "This means, that more data should be added or features reduced.\n",
    "I would try to reduce the features first and then augment data to see if this improves results.\n",
    "\n",
    "Anyway, this is a proof of concept.\n",
    "\n",
    "The next step will be to create own models (starting with dense layers, not using CNN at first) and to improve and compare those.\n",
    "\n",
    "All in all it is to say, that the proof of concept works."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}